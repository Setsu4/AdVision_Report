{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# オブジェクト除去とインペインティング\n",
        "\n",
        "このJupyter Notebookでは、Hugging Faceの`facebook/detr-resnet-50`を使用した物体検出と、`runwayml/stable-diffusion-inpainting`を使用した画像補完（インペインティング）のパイプラインを実装しています。\n",
        "\n",
        "画像内の物体を特定して削除し、その領域を周囲の背景に基づいて補完することができます。"
      ],
      "metadata": {
        "id": "mssHkpucRrxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使い方\n",
        "\n",
        "1. **Google Colabの設定**\n",
        "   - [ランタイム] > [ランタイムのタイプを変更] から「ハードウェアアクセラレータ」を「GPU」に設定してください。\n",
        "\n",
        "2. **ライブラリのインストール**:\n",
        "   - 初めに以下のコードセルを実行し、必要なライブラリをインストールしてください。\n",
        "   ```bash\n",
        "   !pip install transformers diffusers pillow opencv-python-headless\n",
        "   !pip install transformers diffusers pillow opencv-python-headless numpy\n",
        "   ```\n",
        "\n",
        "3. **画像の準備**:\n",
        "   - `001.jpg`という名前の画像ファイルをアップロードしてください。このファイルが処理の対象となります。\n",
        "   - 別の画像を使用する場合は、プログラム内でファイル名を変更してください。\n",
        "4. **セルを順次実行**:\n",
        "   - Notebookの各セルを上から順に実行してください。物体検出、削除、補完の各ステップが進行します。\n",
        "5. **出力の確認**:\n",
        "   - 結果として以下のファイルが生成されます：\n",
        "     - `annotated_image.jpg`: 検出された物体とバウンディングボックスが描画された画像。\n",
        "     - `removed_image.jpg`: 選択した物体が削除された画像。\n",
        "     - `result_image.jpg`: 削除された領域が補完された最終的な画像。"
      ],
      "metadata": {
        "id": "oMVhJa2qRyqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers diffusers pillow opencv-python-headless\n",
        "!pip install transformers diffusers pillow opencv-python-headless numpy"
      ],
      "metadata": {
        "id": "iu7plZcwqRJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 必要なライブラリのインポート\n",
        "\n",
        "以下のセルでは、物体検出と画像補完に必要なライブラリをインポートします。"
      ],
      "metadata": {
        "id": "LJZQ2y6aR8-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "from diffusers import StableDiffusionInpaintPipeline"
      ],
      "metadata": {
        "id": "yeck5p9pvVZi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 関数の定義\n",
        "\n",
        "- `load_image`: 画像を読み込む関数です。\n",
        "- `detect_objects`: 物体検出を行い、検出結果を返します。\n",
        "- `draw_bounding_boxes`: 検出した物体を画像上に描画します。\n",
        "- `save_image`: 画像を保存する関数です。\n",
        "- `apply_gamma_correction`: ガンマ補正を適用する関数です。\n",
        "- `inpaint_image`: 選択した物体を削除し、削除された領域を補完します。\n",
        "- `generate_surrounding_mask_color`: マスク領域の周囲の平均色を生成する関数です。\n",
        "- `resize_to_original`: 画像を元のサイズにリサイズする関数です。\n",
        "- `blend_images`: 補完後の画像を元画像と融合します。\n",
        "- `main`: メイン関数。"
      ],
      "metadata": {
        "id": "H1nYKVAISETB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return image"
      ],
      "metadata": {
        "id": "ZR5iTf64vXFW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(image, model, processor):\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    target_sizes = torch.tensor([image.size[::-1]])\n",
        "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
        "    return results"
      ],
      "metadata": {
        "id": "4sbBhXPXvdG4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bounding_boxes(image, results):\n",
        "    image_np = np.array(image, dtype=np.uint8)\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 1.2  # 大きめのフォントサイズ\n",
        "    thickness = 3  # 太めの線\n",
        "\n",
        "    for idx, (box, score, label) in enumerate(zip(results[\"boxes\"], results[\"scores\"], results[\"labels\"])):\n",
        "        box = [int(coord) for coord in box.tolist()]\n",
        "        cv2.rectangle(image_np, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
        "        text = f\"{idx}\"\n",
        "        text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
        "        text_x = box[0]\n",
        "        text_y = box[1] - 10 if box[1] - 10 > 10 else box[1] + 10\n",
        "        cv2.putText(image_np, text, (text_x, text_y), font, font_scale, (0, 255, 0), thickness)\n",
        "    return image_np"
      ],
      "metadata": {
        "id": "oljgkb-wGbub"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image(image, file_path):\n",
        "    # Ensure image is in RGB and uint8 format before saving\n",
        "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
        "        image = np.clip(image, 0, 255).astype(np.uint8)\n",
        "    Image.fromarray(image).save(file_path)"
      ],
      "metadata": {
        "id": "I2G5OQvoGJtN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_gamma_correction(image, gamma=2.2):\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in range(256)]).astype(\"uint8\")\n",
        "    return cv2.LUT(image, table)"
      ],
      "metadata": {
        "id": "Sn8zvtbQGLyM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inpaint_image(image, mask, inpaint_pipeline):\n",
        "    image = Image.fromarray(image)\n",
        "    mask = Image.fromarray(mask).convert(\"L\")\n",
        "    result = inpaint_pipeline(prompt=\"background continuation, seamless blend\", image=image, mask_image=mask).images[0]\n",
        "    return np.array(result)"
      ],
      "metadata": {
        "id": "ZWr0cy95GQFg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_surrounding_mask_color(image, mask):\n",
        "    image_np = np.array(image)\n",
        "    coords = np.column_stack(np.where(mask == 255))\n",
        "    if len(coords) == 0:\n",
        "        return image_np\n",
        "\n",
        "    min_row, min_col = coords.min(axis=0)\n",
        "    max_row, max_col = coords.max(axis=0)\n",
        "\n",
        "    surrounding_pixels = image_np[max(0, min_row - 1):max_row + 2, max(0, min_col - 1):max_col + 2]\n",
        "    average_color = surrounding_pixels.mean(axis=(0, 1)).astype(np.uint8)\n",
        "\n",
        "    return average_color"
      ],
      "metadata": {
        "id": "EediSDFFGULY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_to_original(image, original_size):\n",
        "    return cv2.resize(image, (original_size[0], original_size[1]), interpolation=cv2.INTER_LANCZOS4)"
      ],
      "metadata": {
        "id": "F-UFVmh_GdoW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blend_images(original_image, inpainted_image, mask):\n",
        "    blended_image = np.array(original_image).copy()\n",
        "    blended_image[mask == 255] = inpainted_image[mask == 255]\n",
        "    return blended_image"
      ],
      "metadata": {
        "id": "NECMW-CfGgdL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2HSRFO08U5NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    image_path = \"/content/drive/MyDrive/B4/アドバンスドビジョン/003.jpg\"\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(\"画像ファイルが見つかりません。\")\n",
        "        return\n",
        "\n",
        "    print(\"モデルを読み込んでいます...\")\n",
        "    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "    model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
        "\n",
        "    inpaint_pipeline = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    print(\"画像を処理しています...\")\n",
        "    image = load_image(image_path)\n",
        "    original_size = image.size\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Apply gamma correction to ensure consistent color\n",
        "    image_np = apply_gamma_correction(image_np)\n",
        "\n",
        "    results = detect_objects(image, model, processor)\n",
        "\n",
        "    print(\"検出結果を描画しています...\")\n",
        "    annotated_image = draw_bounding_boxes(image_np, results)\n",
        "    output_annotated_path = \"annotated_image.jpg\"\n",
        "    save_image(annotated_image, output_annotated_path)\n",
        "    print(f\"物体認識結果を '{output_annotated_path}' に保存しました。画像ビューアで確認してください。\")\n",
        "\n",
        "    selected_indices = input(\"削除したい物体の番号をカンマ区切りで入力してください（例: 0,2,3）: \")\n",
        "    selected_indices = [int(idx.strip()) for idx in selected_indices.split(\",\") if idx.strip().isdigit()]\n",
        "\n",
        "    print(\"マスクを生成しています...\")\n",
        "    mask = np.zeros((image.height, image.width), dtype=np.uint8)\n",
        "    for selected_idx in selected_indices:\n",
        "        if selected_idx < 0 or selected_idx >= len(results[\"boxes\"]):\n",
        "            print(f\"無効な番号: {selected_idx}\")\n",
        "            continue\n",
        "\n",
        "        box = [int(coord) for coord in results[\"boxes\"][selected_idx].tolist()]\n",
        "        mask[box[1]:box[3], box[0]:box[2]] = 255\n",
        "\n",
        "    print(\"マスク部分の色を周辺に合わせています...\")\n",
        "    removed_image = np.array(image_np)\n",
        "    average_color = generate_surrounding_mask_color(image, mask)\n",
        "    removed_image[mask == 255] = average_color\n",
        "\n",
        "    output_removed_path = \"removed_image.jpg\"\n",
        "    save_image(removed_image, output_removed_path)\n",
        "    print(f\"選択した物体を削除した画像を '{output_removed_path}' に保存しました。画像ビューアで確認してください。\")\n",
        "\n",
        "    print(\"画像を補完しています...\")\n",
        "    # 制限付き範囲でのみ補完を実行\n",
        "    inpainted_image = inpaint_pipeline(\n",
        "        prompt=\"background continuation, seamless blend\",\n",
        "        image=Image.fromarray(removed_image),\n",
        "        mask_image=Image.fromarray(mask).convert(\"L\")\n",
        "    ).images[0]\n",
        "\n",
        "    # リサイズして元の画像と一致させる\n",
        "    inpainted_image_resized = resize_to_original(np.array(inpainted_image), removed_image.shape[:2][::-1])\n",
        "\n",
        "    # マスク範囲を元に戻しつつ補完\n",
        "    result_image = blend_images(removed_image, inpainted_image_resized, mask)\n",
        "\n",
        "    output_result_path = \"result_image.jpg\"\n",
        "    save_image(result_image, output_result_path)\n",
        "    print(f\"補完結果を '{output_result_path}' に保存しました。画像ビューアで確認してください。\")"
      ],
      "metadata": {
        "id": "m1CD3QExGifg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "kbo8_JbMGm8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}